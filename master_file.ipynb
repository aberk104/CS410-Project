{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The master_file serves as the glue for all other files in the project.  It is the central file to load training and test data, tag the addresses, standardize the addresses, and compare the different address lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from address_compare import standardizers as stndrdzr\n",
    "from address_compare import comparers as comps\n",
    "from address_compare import matcher as mtch\n",
    "from address_compare.crf_tagger import AddressTagger\n",
    "from address_compare import address_randomizer as add_rndm\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Editable parameters to control the functions\n",
    "retrain_crf_tagger = False\n",
    "standardize_addresses = True\n",
    "num_rndm_addresses_to_create = 100\n",
    "use_raw_address_files = True #if False, only the specified number of randomly created addresses above will be used\n",
    "group_addresses_intra_list = True #if False, duplicates within a list will not be grouped in order to easily compare against the golden/manual matches\n",
    "\n",
    "field_name_raw_addresses = 'Single String Address'\n",
    "field_name_record_id = 'Record_ID'\n",
    "\n",
    "file_location_raw_addresses_1 = 'data\\\\MarijuanaApplicants - test data list 1.xlsx'\n",
    "file_location_raw_addresses_2 = 'data\\\\MarijuanaApplicants - test data list 2.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholder for reading/calling the training data for the CRF Tagger and sending the training data to train the model\n",
    "if retrain_crf_tagger:\n",
    "    with open('data/tagged_addresses.json') as f:\n",
    "        td = json.load(f)\n",
    "    \n",
    "    #send training data to CRF tagger to train the model here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholder for reading/calling the 2 lists of raw addresses\n",
    "if use_raw_address_files:\n",
    "    raw_address_list_1 = pd.read_excel(file_location_raw_addresses_1)\n",
    "    raw_address_list_2 = pd.read_excel(file_location_raw_addresses_2)\n",
    "else:\n",
    "    raw_address_list_1 = add_rndm.random_addresses(num_rndm_addresses_to_create, field_name_raw_addresses)\n",
    "    raw_address_list_2 = add_rndm.random_addresses(num_rndm_addresses_to_create, field_name_raw_addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add a field called Record_ID if it doesn't already exist in the raw address files\n",
    "raw_address_list_1 = stndrdzr.record_id_addition(raw_address_list_1, field_name_record_id)\n",
    "raw_address_list_2 = stndrdzr.record_id_addition(raw_address_list_2, field_name_record_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add Empty Missing Columns to Dataframe\n",
    "missing_columns = ['CITY','STATE','ZIP_CODE','UNKNOWN']\n",
    "raw_address_list_1 = stndrdzr.empty_column_addition(raw_address_list_1, missing_columns)\n",
    "raw_address_list_2 = stndrdzr.empty_column_addition(raw_address_list_2, missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate AddressTagger object with default options, which gives the model trained in `Train CRF Model`.ipynb\n",
    "at = AddressTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call the trained CRF Tagger on the 2 lists of raw addresses\n",
    "tagged_address_list_1 = at.series_to_address_df(raw_address_list_1[field_name_raw_addresses], standardize = standardize_addresses)\n",
    "tagged_address_list_2 = at.series_to_address_df(raw_address_list_2[field_name_raw_addresses], standardize = standardize_addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check for Errors in Zip Codes and Replace City Names with Primary City from Zip Code\n",
    "raw_address_list_1 = stndrdzr.fix_cities_zips(raw_address_list_1)\n",
    "raw_address_list_2 = stndrdzr.fix_cities_zips(raw_address_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add Remaining Columns from Raw Address Dataframes to Tagged Address Dataframes\n",
    "joined_address_list_1 = tagged_address_list_1.join(raw_address_list_1[['Record_ID','CITY','STATE','ZIP_CODE','UNKNOWN','Zip_Code_Error']])\n",
    "joined_address_list_2 = tagged_address_list_2.join(raw_address_list_2[['Record_ID','CITY','STATE','ZIP_CODE','UNKNOWN','Zip_Code_Error']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove Addresses with Zip Code Errors (I.e., where the Zip Code is not valid for the given state)\n",
    "error_addresses_list_1 = joined_address_list_1.where(joined_address_list_1.Zip_Code_Error == \"Yes\").dropna()\n",
    "error_addresses_list_2 = joined_address_list_2.where(joined_address_list_2.Zip_Code_Error == \"Yes\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Addresses without Zip Code Errors (I.e., where the Zip Code is valid for the given state)\n",
    "nonerror_addresses_list_1 = joined_address_list_1.where(joined_address_list_1.Zip_Code_Error == \"No\").dropna()\n",
    "nonerror_addresses_list_2 = joined_address_list_2.where(joined_address_list_2.Zip_Code_Error == \"No\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nonerror_addresses_list_1 = nonerror_addresses_list_1.astype({'Record_ID':'int', 'ZIP_CODE':'int'})\n",
    "nonerror_addresses_list_2 = nonerror_addresses_list_2.astype({'Record_ID':'int', 'ZIP_CODE':'int'})\n",
    "nonerror_addresses_list_1 = nonerror_addresses_list_1.astype({'Record_ID':'str', 'ZIP_CODE':'str'})\n",
    "nonerror_addresses_list_2 = nonerror_addresses_list_2.astype({'Record_ID':'str', 'ZIP_CODE':'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intra-Grouping of Tagged Address Lists to Consolidate Duplicates\n",
    "if group_addresses_intra_list:\n",
    "    grouped_address_list_1 = stndrdzr.consolidate_address_list(nonerror_addresses_list_1)\n",
    "    grouped_address_list_2 = stndrdzr.consolidate_address_list(nonerror_addresses_list_2)\n",
    "else:\n",
    "    grouped_address_list_1 = nonerror_addresses_list_1.copy()\n",
    "    grouped_address_list_2 = nonerror_addresses_list_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call Either the Exact Match or Learning Match Functions to match the 2 lists\n",
    "exact_matches = mtch.exact_matcher(grouped_address_list_1, grouped_address_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unmatched_address_list_1 = grouped_address_list_1.mask(grouped_address_list_1.Record_ID.isin(exact_matches['Record_ID_list_1'])).dropna()\n",
    "unmatched_address_list_2 = grouped_address_list_2.mask(grouped_address_list_2.Record_ID.isin(exact_matches['Record_ID_list_2'])).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionary of DataFrames for Excel File\n",
    "dataframes_for_excel = {'raw_addresses_list_1': raw_address_list_1, 'raw_addresses_list2': raw_address_list_2,\n",
    "                        'zip_errors_list1': error_addresses_list_1, 'zip_errors_list2': error_addresses_list_2,\n",
    "                       'exact_matches': exact_matches, 'unmatched_list_1': unmatched_address_list_1,\n",
    "                       'unmatched_list_2': unmatched_address_list_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write Dict of DataFrames to Excel\n",
    "writer = pd.ExcelWriter('output\\\\raw_to_matched_addresses.xlsx', engine='xlsxwriter')\n",
    "for sheet, frame in  dataframes_for_excel.items():\n",
    "    frame.to_excel(writer, sheet_name = sheet)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Output of Exact Match to Manually Tagged Matches\n",
    "if not group_addresses_intra_list:\n",
    "    manual_matches = pd.read_excel('data\\\\marijuana applicants test data - correct matches.xlsx', dtype=str)\n",
    "    golden_exact_matches = manual_matches.where(manual_matches.Match_Type.isin([\"Exact\",\"Standardized Exact\"])).dropna().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not group_addresses_intra_list:\n",
    "    join_cols = ['Record_ID_list_1','Record_ID_list_2']\n",
    "    subset_columns_exact_matches = exact_matches[join_cols].copy()\n",
    "    subset_columns_exact_matches['row_index'] = subset_columns_exact_matches.index\n",
    "    subset_cols_golden_exact_matches = golden_exact_matches[join_cols].copy()\n",
    "    subset_cols_golden_exact_matches['row_index'] = subset_cols_golden_exact_matches.index\n",
    "\n",
    "    test_vs_golden_compare = mtch.exact_matcher(subset_columns_exact_matches, subset_cols_golden_exact_matches, join_cols)\n",
    "    print (test_vs_golden_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not group_addresses_intra_list:\n",
    "    missing_golden_matches = subset_cols_golden_exact_matches.mask(subset_cols_golden_exact_matches.row_index.isin(test_vs_golden_compare.row_index_list_2)).dropna()\n",
    "    print (missing_golden_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not group_addresses_intra_list:\n",
    "    matches_not_in_golden = subset_columns_exact_matches.mask(subset_columns_exact_matches.row_index.isin(test_vs_golden_compare.row_index_list_1)).dropna()\n",
    "    print (matches_not_in_golden)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
