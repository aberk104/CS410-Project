{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The master_file is an example of how the address_compare library can be used to load training and test data, tag the addresses, standardize the addresses, and compare the different address lists.  It can serve as a reusable program by updating the input parameters.  If ground truth files are available, it will also show how well the tagger and compare functions perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from address_compare import standardizers as stndrdzr\n",
    "from address_compare import matcher as mtch\n",
    "from address_compare.crf_tagger import AddressTagger\n",
    "from address_compare import address_randomizer as add_rndm\n",
    "import json\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Editable parameters to control the functions/program\n",
    "retrain_crf_tagger = False #if True, the specified training file will be used to retrain the CRF Tagger\n",
    "standardize_addresses = True #if True, the tagged address components will be standardized (changed to upper case, unit types, street types, etc. changed to long form names)\n",
    "num_rndm_addresses_to_create = 100 #if use_raw_address_files = False, the number of addresses that will be randomly created for use in the tagger and compare functions\n",
    "use_raw_address_files = True #if False, only the specified number of randomly created addresses above will be used\n",
    "group_addresses_intra_list = False #if False, duplicates within a list will not be grouped in order to easily compare against the golden/manual matches\n",
    "\n",
    "view_address_tagger_metrics_against_single_file_only = True #if True, the file will only run the address tagger against the file in file_location_tagger_test_metrics and will calculate the accuracy of the tagger\n",
    "\n",
    "field_name_raw_addresses = 'Single String Address' #represents the name of the field in the raw address files containing the raw address (street information)\n",
    "field_name_record_id = 'Record_ID' #represents the name of the field containing the Record ID in the raw files; if not present in the raw files, populate with None\n",
    "\n",
    "file_location_raw_addresses_1 = 'data\\\\MarijuanaApplicants - test data list 1.xlsx'\n",
    "file_location_raw_addresses_2 = 'data\\\\MarijuanaApplicants - test data list 2.xlsx'\n",
    "\n",
    "file_name_ground_truth_matches = 'data\\\\marijuana applicants test data - correct matches.xlsx' #if group_addresses_intra_list = False, the name of the file that contains the ground truth matches between raw address list 1 and raw address list 2\n",
    "file_name_for_matched_address_output = 'output\\\\raw_to_matched_addresses.xlsx' #file name to where the output will be written\n",
    "\n",
    "#file_location_tagger_test_metrics = 'data\\\\standardized tagged washington state addresses.xlsx' #only used if view_address_tagger_metrics.. == True\n",
    "file_location_tagger_test_metrics = 'data\\\\tagged standardized colorado Stores.xlsx' #only used if view_address_tagger_metrics.. == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholder for reading/calling the training data for the CRF Tagger and sending the training data to train the model\n",
    "if retrain_crf_tagger:\n",
    "    with open('data/tagged_addresses.json') as f:\n",
    "        td = json.load(f)\n",
    "    \n",
    "    #send training data to CRF tagger to train the model here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tagger accuracy =  0.7713717693836978\n",
      "column =  UNIT_TYPE precision =  0.950298210736 recall =  0.950298210736 f1score =  0.950298210736\n",
      "column =  UNIT_NUMBER precision =  0.928429423459 recall =  0.928429423459 f1score =  0.928429423459\n",
      "column =  STREET_NUMBER precision =  0.936381709742 recall =  0.936381709742 f1score =  0.936381709742\n",
      "column =  PRE_DIRECTION precision =  0.984095427435 recall =  0.984095427435 f1score =  0.984095427435\n",
      "column =  STREET_NAME precision =  0.799204771372 recall =  0.799204771372 f1score =  0.799204771372\n",
      "column =  STREET_TYPE precision =  0.838966202783 recall =  0.838966202783 f1score =  0.838966202783\n",
      "column =  POST_DIRECTION precision =  0.990059642147 recall =  0.990059642147 f1score =  0.990059642147\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Run Single File against Tagger and Calculate Accuracy\n",
    "if view_address_tagger_metrics_against_single_file_only:\n",
    "    test_file = pd.read_excel(file_location_tagger_test_metrics, keep_default_na=False, dtype=str)\n",
    "    test_file = stndrdzr.record_id_addition(test_file, field_name_record_id)\n",
    "    tagger = AddressTagger()\n",
    "    tagged_test_file = tagger.series_to_address_df(test_file[field_name_raw_addresses], standardize = standardize_addresses)\n",
    "    crf_tagged_test_file = tagged_test_file.join(test_file['Record_ID'])\n",
    "    \n",
    "    ground_truth_columns = ['Record_ID', 'Tagged Street Number','Tagged Pre Street Direction','Tagged Street Name','Tagged Street Type','Tagged Post Street Direction','Tagged Unit Type','Tagged Unit Number']\n",
    "    \n",
    "    manual_tagged_test_file = test_file[ground_truth_columns].copy()\n",
    "    manual_tagged_test_file = manual_tagged_test_file.rename(columns={'Tagged Street Number':'STREET_NUMBER',\n",
    "                                                                     'Tagged Pre Street Direction':'PRE_DIRECTION',\n",
    "                                                                     'Tagged Street Name':'STREET_NAME',\n",
    "                                                                     'Tagged Street Type':'STREET_TYPE',\n",
    "                                                                     'Tagged Post Street Direction':'POST_DIRECTION',\n",
    "                                                                     'Tagged Unit Type':'UNIT_TYPE',\n",
    "                                                                     'Tagged Unit Number':'UNIT_NUMBER'})\n",
    "\n",
    "    cols_for_matcher = ['UNIT_TYPE','UNIT_NUMBER','STREET_NUMBER','PRE_DIRECTION','STREET_NAME','STREET_TYPE','POST_DIRECTION']\n",
    "    correctly_tagged_addresses = mtch.exact_matcher(crf_tagged_test_file, manual_tagged_test_file, cols_for_matcher)\n",
    "    \n",
    "    incorrectly_tagged_addresses = crf_tagged_test_file.mask(crf_tagged_test_file.Record_ID.isin(correctly_tagged_addresses['Record_ID_list_1'])).dropna()\n",
    "    incorrectly_tagged_addresses = incorrectly_tagged_addresses.merge(test_file[ground_truth_columns], on='Record_ID')\n",
    "\n",
    "    total_records = crf_tagged_test_file.shape[0]\n",
    "    correctly_tagged = correctly_tagged_addresses.shape[0]\n",
    "    incorrectly_tagged = incorrectly_tagged_addresses.shape[0]\n",
    "    \n",
    "    tagger_accuracy = correctly_tagged / total_records\n",
    "    print ('tagger accuracy = ', tagger_accuracy)\n",
    "    \n",
    "    for col in cols_for_matcher:\n",
    "        precision, recall, fscore, ignore = sklearn.metrics.precision_recall_fscore_support(manual_tagged_test_file[col], crf_tagged_test_file[col], average='micro')\n",
    "        print ('column = ', col, 'precision = ', precision, 'recall = ', recall, 'f1score = ',fscore)\n",
    "    \n",
    "    # Dictionary of DataFrames for Excel Tagger Test File\n",
    "    dataframes_for_tagger_excel = {'test_data_file': test_file, \n",
    "                                   'crf_tagger_output': crf_tagged_test_file,\n",
    "                                   'ground_truth_test_file': manual_tagged_test_file, \n",
    "                                   'correctly_tagged': correctly_tagged_addresses,\n",
    "                                   'incorrectly_tagged': incorrectly_tagged_addresses}\n",
    "    \n",
    "    # Write Dict of DataFrames to Excel\n",
    "    tagger_writer = pd.ExcelWriter('output\\\\tagger accuracy output.xlsx', engine='xlsxwriter')\n",
    "    for sheet, frame in  dataframes_for_tagger_excel.items():\n",
    "        frame.to_excel(tagger_writer, sheet_name = sheet)\n",
    "    tagger_writer.save()\n",
    "    \n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholder for reading/calling the 2 lists of raw addresses\n",
    "if use_raw_address_files:\n",
    "    raw_address_list_1 = pd.read_excel(file_location_raw_addresses_1)\n",
    "    raw_address_list_2 = pd.read_excel(file_location_raw_addresses_2)\n",
    "else:\n",
    "    raw_address_list_1 = add_rndm.random_addresses(num_rndm_addresses_to_create, field_name_raw_addresses)\n",
    "    raw_address_list_2 = add_rndm.random_addresses(num_rndm_addresses_to_create, field_name_raw_addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add a field called Record_ID if it doesn't already exist in the raw address files\n",
    "raw_address_list_1 = stndrdzr.record_id_addition(raw_address_list_1, field_name_record_id)\n",
    "raw_address_list_2 = stndrdzr.record_id_addition(raw_address_list_2, field_name_record_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add Empty Missing Columns to Dataframe\n",
    "missing_columns = ['CITY','STATE','ZIP_CODE','UNKNOWN']\n",
    "raw_address_list_1 = stndrdzr.empty_column_addition(raw_address_list_1, missing_columns)\n",
    "raw_address_list_2 = stndrdzr.empty_column_addition(raw_address_list_2, missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate AddressTagger object with default options, which gives the model trained in `Train CRF Model`.ipynb\n",
    "at = AddressTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call the trained CRF Tagger on the 2 lists of raw addresses\n",
    "tagged_address_list_1 = at.series_to_address_df(raw_address_list_1[field_name_raw_addresses], standardize = standardize_addresses)\n",
    "tagged_address_list_2 = at.series_to_address_df(raw_address_list_2[field_name_raw_addresses], standardize = standardize_addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check for Errors in Zip Codes and Replace City Names with Primary City from Zip Code\n",
    "raw_address_list_1 = stndrdzr.fix_cities_zips(raw_address_list_1)\n",
    "raw_address_list_2 = stndrdzr.fix_cities_zips(raw_address_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add Remaining Columns from Raw Address Dataframes to Tagged Address Dataframes\n",
    "joined_address_list_1 = tagged_address_list_1.join(raw_address_list_1[['Record_ID','CITY','STATE','ZIP_CODE','UNKNOWN','Zip_Code_Error']])\n",
    "joined_address_list_2 = tagged_address_list_2.join(raw_address_list_2[['Record_ID','CITY','STATE','ZIP_CODE','UNKNOWN','Zip_Code_Error']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove Addresses with Zip Code Errors (I.e., where the Zip Code is not valid for the given state)\n",
    "error_addresses_list_1 = joined_address_list_1.where(joined_address_list_1.Zip_Code_Error == \"Yes\").dropna()\n",
    "error_addresses_list_2 = joined_address_list_2.where(joined_address_list_2.Zip_Code_Error == \"Yes\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only Addresses without Zip Code Errors (I.e., where the Zip Code is valid for the given state)\n",
    "nonerror_addresses_list_1 = joined_address_list_1.where(joined_address_list_1.Zip_Code_Error == \"No\").dropna()\n",
    "nonerror_addresses_list_2 = joined_address_list_2.where(joined_address_list_2.Zip_Code_Error == \"No\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nonerror_addresses_list_1 = nonerror_addresses_list_1.astype({'Record_ID':'int', 'ZIP_CODE':'int'})\n",
    "nonerror_addresses_list_2 = nonerror_addresses_list_2.astype({'Record_ID':'int', 'ZIP_CODE':'int'})\n",
    "nonerror_addresses_list_1 = nonerror_addresses_list_1.astype({'Record_ID':'str', 'ZIP_CODE':'str'})\n",
    "nonerror_addresses_list_2 = nonerror_addresses_list_2.astype({'Record_ID':'str', 'ZIP_CODE':'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Intra-Grouping of Tagged Address Lists to Consolidate Duplicates\n",
    "if group_addresses_intra_list:\n",
    "    grouped_address_list_1 = stndrdzr.consolidate_address_list(nonerror_addresses_list_1)\n",
    "    grouped_address_list_2 = stndrdzr.consolidate_address_list(nonerror_addresses_list_2)\n",
    "else:\n",
    "    grouped_address_list_1 = nonerror_addresses_list_1.copy()\n",
    "    grouped_address_list_2 = nonerror_addresses_list_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call Either the Exact Match or Learning Match Functions to match the 2 lists\n",
    "exact_matches = mtch.exact_matcher(grouped_address_list_1, grouped_address_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unmatched_address_list_1 = grouped_address_list_1.mask(grouped_address_list_1.Record_ID.isin(exact_matches['Record_ID_list_1'])).dropna()\n",
    "unmatched_address_list_2 = grouped_address_list_2.mask(grouped_address_list_2.Record_ID.isin(exact_matches['Record_ID_list_2'])).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionary of DataFrames for Excel File\n",
    "dataframes_for_excel = {'raw_addresses_list_1': raw_address_list_1, 'raw_addresses_list2': raw_address_list_2,\n",
    "                        'zip_errors_list1': error_addresses_list_1, 'zip_errors_list2': error_addresses_list_2,\n",
    "                       'exact_matches': exact_matches, 'unmatched_list_1': unmatched_address_list_1,\n",
    "                       'unmatched_list_2': unmatched_address_list_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write Dict of DataFrames to Excel\n",
    "writer = pd.ExcelWriter(file_name_for_matched_address_output, engine='xlsxwriter')\n",
    "for sheet, frame in  dataframes_for_excel.items():\n",
    "    frame.to_excel(writer, sheet_name = sheet)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare Output of Exact Match to Manually Tagged Matches\n",
    "if not group_addresses_intra_list:\n",
    "    manual_matches = pd.read_excel(file_name_ground_truth_matches, dtype=str)\n",
    "    golden_exact_matches = manual_matches.where(manual_matches.Match_Type.isin([\"Exact\",\"Standardized Exact\"])).dropna().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not group_addresses_intra_list:\n",
    "    join_cols = ['Record_ID_list_1','Record_ID_list_2']\n",
    "    subset_columns_exact_matches = exact_matches[join_cols].copy()\n",
    "    subset_columns_exact_matches['row_index'] = subset_columns_exact_matches.index\n",
    "    subset_cols_golden_exact_matches = golden_exact_matches[join_cols].copy()\n",
    "    subset_cols_golden_exact_matches['row_index'] = subset_cols_golden_exact_matches.index\n",
    "    \n",
    "    subset_columns_exact_matches = subset_columns_exact_matches.astype(str)\n",
    "    subset_cols_golden_exact_matches = subset_cols_golden_exact_matches.astype(str)\n",
    "    \n",
    "    test_vs_golden_compare = mtch.exact_matcher(subset_columns_exact_matches, subset_cols_golden_exact_matches, join_cols)\n",
    "    print (test_vs_golden_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not group_addresses_intra_list:\n",
    "    missing_golden_matches = subset_cols_golden_exact_matches.mask(subset_cols_golden_exact_matches.row_index.isin(test_vs_golden_compare.row_index_list_2)).dropna()\n",
    "    print (missing_golden_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not group_addresses_intra_list:\n",
    "    matches_not_in_golden = subset_columns_exact_matches.mask(subset_columns_exact_matches.row_index.isin(test_vs_golden_compare.row_index_list_1)).dropna()\n",
    "    print (matches_not_in_golden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not group_addresses_intra_list:\n",
    "    total_records_list_1 = raw_address_list_1.shape[0]\n",
    "    total_records_list_2 = raw_address_list_2.shape[0]\n",
    "    total_modeled_matches = exact_matches.shape[0]\n",
    "    total_manual_exact_matches = golden_exact_matches.shape[0]\n",
    "    total_correct_positive_matches = test_vs_golden_compare.shape[0]\n",
    "    false_negatives = missing_golden_matches.shape[0]\n",
    "    false_positives = matches_not_in_golden.shape[0]\n",
    "    \n",
    "    accuracy_list_1 = (total_records_list_1 - (false_negatives + false_positives)) / total_records_list_1\n",
    "    accuracy_list_2 = (total_records_list_2 - (false_negatives + false_positives)) / total_records_list_2\n",
    "    precision = total_correct_positive_matches / (total_correct_positive_matches + false_positives)\n",
    "    recall = total_correct_positive_matches / (total_correct_positive_matches + false_negatives)\n",
    "    \n",
    "    print ('list 1 accuracy = ', accuracy_list_1)\n",
    "    print ('list 2 accuracy = ', accuracy_list_2)\n",
    "    print ('precision = ', precision)\n",
    "    print ('recall = ', recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
