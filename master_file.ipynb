{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The master_file is an example of how the address_compare library can be used to load training and test data, tag the addresses, standardize the addresses, and compare the different address lists.  It can serve as a reusable program by updating the input parameters.  If ground truth files are available, it will also show how well the tagger and compare functions perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     address_1                         address_2  match\n",
      "0        #3672, 84750 E 33 LN         BLDG 3672 - 84750 E 33 LN    True\n",
      "1        #3672, 84750 E 33 LN       BLDG 3672 - 84750 E 33rd LN    True\n",
      "2        #3672, 84750 E 33 LN           BLDG 3672-84750 E 33 LN    True\n",
      "3        #3672, 84750 E 33 LN         BLDG 3672-84750 E 33rd LN    True\n",
      "4        #3672, 84750 E 33 LN          BLDG 3672, 84750 E 33 LN    True\n",
      "5        #3672, 84750 E 33 LN        BLDG 3672, 84750 E 33rd LN    True\n",
      "6        #3672, 84750 E 33 LN           84750 E 33 LN, BLDG 3672   True\n",
      "7        #3672, 84750 E 33 LN         84750 E 33rd LN, BLDG 3672   True\n",
      "8        #3672, 84750 E 33 LN              3672 - 84750 E 33 LN    True\n",
      "9        #3672, 84750 E 33 LN            3672 - 84750 E 33rd LN    True\n",
      "10  BLDG 3672 - 84750 E 33 LN           BLDG 3672-84750 E 33 LN    True\n",
      "11  BLDG 3672 - 84750 E 33 LN         BLDG 3672-84750 E 33rd LN    True\n",
      "12  BLDG 3672 - 84750 E 33 LN          BLDG 3672, 84750 E 33 LN    True\n",
      "13  BLDG 3672 - 84750 E 33 LN        BLDG 3672, 84750 E 33rd LN    True\n",
      "14  BLDG 3672 - 84750 E 33 LN           84750 E 33 LN, BLDG 3672   True\n",
      "15  BLDG 3672 - 84750 E 33 LN         84750 E 33rd LN, BLDG 3672   True\n",
      "16  BLDG 3672 - 84750 E 33 LN              3672 - 84750 E 33 LN    True\n",
      "17  BLDG 3672 - 84750 E 33 LN            3672 - 84750 E 33rd LN    True\n",
      "18    BLDG 3672-84750 E 33 LN          BLDG 3672, 84750 E 33 LN    True\n",
      "19    BLDG 3672-84750 E 33 LN        BLDG 3672, 84750 E 33rd LN    True\n",
      "20    BLDG 3672-84750 E 33 LN           84750 E 33 LN, BLDG 3672   True\n",
      "21    BLDG 3672-84750 E 33 LN         84750 E 33rd LN, BLDG 3672   True\n",
      "22    BLDG 3672-84750 E 33 LN              3672 - 84750 E 33 LN    True\n",
      "23    BLDG 3672-84750 E 33 LN            3672 - 84750 E 33rd LN    True\n",
      "24   BLDG 3672, 84750 E 33 LN           84750 E 33 LN, BLDG 3672   True\n",
      "25   BLDG 3672, 84750 E 33 LN         84750 E 33rd LN, BLDG 3672   True\n",
      "26   BLDG 3672, 84750 E 33 LN              3672 - 84750 E 33 LN    True\n",
      "27   BLDG 3672, 84750 E 33 LN            3672 - 84750 E 33rd LN    True\n",
      "28    84750 E 33 LN, BLDG 3672             3672 - 84750 E 33 LN    True\n",
      "29    84750 E 33 LN, BLDG 3672           3672 - 84750 E 33rd LN    True\n",
      "30  BLDG 3672 - 84750 E 33 LN         84750 E 33rd LN, BLDG 3672   True\n",
      "31    BLDG 3672-84750 E 33 LN              3672 - 84751 E 33 LN   False\n",
      "32   BLDG 3672, 84750 E 33 LN           #3672, 8476.0 E 33rd LN   False\n",
      "33       #3672, 84750 E 33 LN         BLDG 36729, 84750 E 33 LN   False\n",
      "34    BLDG 3672-84750 E 33 LN        84750 E 33rd LN, BLDG 36726  False\n",
      "35       3672 - 84750 E 33 LN            3672 - 84750 E WALL LN   False\n",
      "36       #3672, 84750 E 33 LN         BLDG 3672-84750 E 33 PKWY   False\n",
      "37       #3672, 84750 E 33 LN           84750 33 LN E, BLDG 3672  False\n",
      "38       3672 - 84750 E 33 LN           BLDG 3672 - 84750 33 LN   False\n",
      "39       #3672, 84750 E 33 LN              84750 - 3672 E 33 LN   False\n",
      "40  BLDG 3672 - 84750 E 33 LN        PH 3355 - 23976 NE 89 PKWY   False\n",
      "41    BLDG 3672-84750 E 33 LN      UNIT C-34368 GEORGE ALLEN RD   False\n",
      "42    84750 E 33 LN, BLDG 3672  #2855, 33524 W KING GEORGE PKWY   False\n",
      "43       #3672, 84750 E 33 LN              77171 FULTON RD, FL C  False\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "from address_compare import standardizers as stndrdzr\n",
    "from address_compare import matcher as mtch\n",
    "from address_compare.tagging import AddressTagger\n",
    "from address_compare import address_randomizer as add_rndm\n",
    "import json\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this notebook is an example of how to use the address_compare library, the following parameters can be changed in order to control the inputs and outputs.  I.e., the following parameters allow this file to be a reusable program sitting on top of the address_compare library.\n",
    "\n",
    "\n",
    "The **run_mode** variable controls which portions of this notebook are run.  Options are:\n",
    "- **'tagger'** = run the address tagger against a single file that also contains the ground truths.  output will show how well the tagger did against the ground truths.  tagger will only run against the file found in @file_location_raw_addresses_1\n",
    "- **'comparer'** = tag 2 separate lists of addresses and find matches between the lists.  no ground truths for comparisons.  no tagger ground truths or match ground truths included. program will run against both @file_location_raw_addresses_1 and @file_location_raw_addresses_2\n",
    "- **'comparer_truths'** = run the comparer and validate the matcher performance against the ground truths. program will run against both @file_location_raw_addresses_1 and @file_location_raw_addresses_2.  in addition, the matched ground truths will be found in @file_name_ground_truth_matches\n",
    "- **'all'** = runs all 3 modes.  i.e., tagger results compared against the ground truths and the matcher results compared against the ground truths.  program will run against both @file_location_raw_addresses_1 and @file_location_raw_addresses_2. in addition, the matched ground truths will be found in @file_name_ground_truth_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "retrain_crf_tagger = False #if True, the specified training file will be used to retrain the CRF Tagger\n",
    "\n",
    "run_mode = 'comparer_truths' #choose from ['tagger','comparer','comparer_truths','all']\n",
    "\n",
    "\n",
    "standardize_addresses = True #if True, the tagged address components will be standardized (changed to upper case, unit types, street types, etc. changed to long form names)\n",
    "\n",
    "use_raw_address_files = True #if False, only the specified number of randomly created addresses above will be used\n",
    "num_rndm_addresses_to_create = 100 #if use_raw_address_files = False, the number of addresses that will be randomly created for use in the tagger and compare functions\n",
    "\n",
    "field_name_raw_addresses = 'Single String Address' #represents the name of the field in the raw address files containing the raw address (street information)\n",
    "field_name_record_id = 'Record_ID' #represents the name of the field containing the Record ID in the raw files; if not present in the raw files, populate with None\n",
    "\n",
    "#file_location_raw_addresses_1 = 'data\\\\standardized tagged washington state addresses.xlsx'\n",
    "#file_location_raw_addresses_1 = 'data\\\\tagged standardized colorado Stores.xlsx'\n",
    "file_location_raw_addresses_1 = 'data\\\\MarijuanaApplicants - test data list 1.xlsx'\n",
    "file_location_raw_addresses_2 = 'data\\\\MarijuanaApplicants - test data list 2.xlsx'\n",
    "\n",
    "file_name_ground_truth_matches = 'data\\\\marijuana applicants test data - correct matches.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholder for reading/calling the training data for the CRF Tagger and sending the training data to train the model\n",
    "if retrain_crf_tagger:\n",
    "    with open('data/tagged_addresses.json') as f:\n",
    "        td = json.load(f)\n",
    "    \n",
    "    #send training data to CRF tagger to train the model here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tagger_vs_ground_truths (file, file_num, field_rec_id, field_raw_address, to_standardize):\n",
    "    test_file = pd.read_excel(file, keep_default_na=False, dtype=str)\n",
    "    test_file = stndrdzr.record_id_addition(test_file, field_rec_id)\n",
    "    \n",
    "    # Add Empty Missing Columns to Dataframe\n",
    "    missing_columns = ['CITY','STATE','ZIP_CODE','UNKNOWN']\n",
    "    test_file = stndrdzr.empty_column_addition(test_file, missing_columns)\n",
    "    \n",
    "    tagger = AddressTagger()\n",
    "    tagged_test_file = tagger.series_to_address_df(test_file[field_raw_address], standardize = to_standardize)\n",
    "    crf_tagged_test_file = tagged_test_file.join(test_file['Record_ID'])\n",
    "    \n",
    "    ground_truth_columns = ['Record_ID', 'Tagged Street Number','Tagged Pre Street Direction','Tagged Street Name','Tagged Street Type','Tagged Post Street Direction','Tagged Unit Type','Tagged Unit Number']\n",
    "    \n",
    "    manual_tagged_test_file = test_file[ground_truth_columns].copy()\n",
    "    manual_tagged_test_file = manual_tagged_test_file.rename(columns={'Tagged Street Number':'STREET_NUMBER',\n",
    "                                                                     'Tagged Pre Street Direction':'PRE_DIRECTION',\n",
    "                                                                     'Tagged Street Name':'STREET_NAME',\n",
    "                                                                     'Tagged Street Type':'STREET_TYPE',\n",
    "                                                                     'Tagged Post Street Direction':'POST_DIRECTION',\n",
    "                                                                     'Tagged Unit Type':'UNIT_TYPE',\n",
    "                                                                     'Tagged Unit Number':'UNIT_NUMBER'})\n",
    "\n",
    "    cols_for_matcher = ['UNIT_TYPE','UNIT_NUMBER','STREET_NUMBER','PRE_DIRECTION','STREET_NAME','STREET_TYPE','POST_DIRECTION']\n",
    "    correctly_tagged_addresses = mtch.exact_matcher(crf_tagged_test_file, manual_tagged_test_file, cols_for_matcher)\n",
    "    \n",
    "    incorrectly_tagged_addresses = crf_tagged_test_file.mask(crf_tagged_test_file.Record_ID.isin(correctly_tagged_addresses['Record_ID_list_1'])).dropna()\n",
    "    incorrectly_tagged_addresses = incorrectly_tagged_addresses.merge(test_file[ground_truth_columns], on='Record_ID')\n",
    "\n",
    "    total_records = crf_tagged_test_file.shape[0]\n",
    "    correctly_tagged = correctly_tagged_addresses.shape[0]\n",
    "    incorrectly_tagged = incorrectly_tagged_addresses.shape[0]\n",
    "    \n",
    "    tagger_accuracy = correctly_tagged / total_records\n",
    "    \n",
    "    metrics_dict = OrderedDict()\n",
    "    precision_dict = OrderedDict()\n",
    "    recall_dict = OrderedDict()\n",
    "    fscore_dict = OrderedDict()\n",
    "    overallacc_dict = OrderedDict()\n",
    "    \n",
    "    for col in cols_for_matcher:\n",
    "        precision, recall, fscore, ignore = sklearn.metrics.precision_recall_fscore_support(manual_tagged_test_file[col], crf_tagged_test_file[col], average='micro')\n",
    "        precision_dict[col] = precision\n",
    "        recall_dict[col] = recall\n",
    "        fscore_dict[col] = fscore\n",
    "        overallacc_dict[col] = None\n",
    "    \n",
    "    precision_dict['overall_accuracy'] = None\n",
    "    recall_dict['overall_accuracy'] = None\n",
    "    fscore_dict['overall_accuracy'] = None\n",
    "    overallacc_dict['overall_accuracy'] = tagger_accuracy  \n",
    "    \n",
    "    metrics_dict['precision'] = precision_dict\n",
    "    metrics_dict['recall'] = recall_dict\n",
    "    metrics_dict['fscore'] = fscore_dict\n",
    "    metrics_dict['overall_accuracy'] = overallacc_dict\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics_dict)\n",
    "    \n",
    "    # Dictionary of DataFrames for Excel Tagger Test File\n",
    "    dataframes_for_tagger_excel = {'test_data_file': test_file, \n",
    "                                   'crf_tagger_output': crf_tagged_test_file,\n",
    "                                   'ground_truth_test_file': manual_tagged_test_file, \n",
    "                                   'correctly_tagged': correctly_tagged_addresses,\n",
    "                                   'incorrectly_tagged': incorrectly_tagged_addresses,\n",
    "                                  'tagger_metrics': metrics_df}\n",
    "    \n",
    "    # Write Dict of DataFrames to Excel\n",
    "    output_name = 'output\\\\file ' + str(file_num) + ' tagger accuracy output.xlsx'\n",
    "    tagger_writer = pd.ExcelWriter(output_name, engine='xlsxwriter')\n",
    "    for sheet, frame in  dataframes_for_tagger_excel.items():\n",
    "        frame.to_excel(tagger_writer, sheet_name = sheet)\n",
    "    tagger_writer.save()\n",
    "    \n",
    "    return test_file, tagged_test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_mode == 'tagger':\n",
    "    raw_address_list_1, tagged_address_list_1 = tagger_vs_ground_truths(file_location_raw_addresses_1, 1, field_name_record_id, field_name_raw_addresses, standardize_addresses)\n",
    "    sys.exit()\n",
    "elif run_mode == 'all':\n",
    "    raw_address_list_1, tagged_address_list_1 = tagger_vs_ground_truths(file_location_raw_addresses_1, 1, field_name_record_id, field_name_raw_addresses, standardize_addresses)\n",
    "    raw_address_list_2, tagged_address_list_2 = tagger_vs_ground_truths(file_location_raw_addresses_2, 2, field_name_record_id, field_name_raw_addresses, standardize_addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholder for reading/calling the 2 lists of raw addresses\n",
    "if run_mode in ['comparer','comparer_truths']:\n",
    "    if use_raw_address_files:\n",
    "        raw_address_list_1 = pd.read_excel(file_location_raw_addresses_1)\n",
    "        raw_address_list_2 = pd.read_excel(file_location_raw_addresses_2)\n",
    "    else:\n",
    "        raw_address_list_1 = add_rndm.random_addresses(num_rndm_addresses_to_create, field_name_raw_addresses)\n",
    "        raw_address_list_2 = add_rndm.random_addresses(num_rndm_addresses_to_create, field_name_raw_addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add a field called Record_ID if it doesn't already exist in the raw address files\n",
    "if run_mode in ['comparer','comparer_truths']:\n",
    "    raw_address_list_1 = stndrdzr.record_id_addition(raw_address_list_1, field_name_record_id)\n",
    "    raw_address_list_2 = stndrdzr.record_id_addition(raw_address_list_2, field_name_record_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add Empty Missing Columns to Dataframe\n",
    "if run_mode in ['comparer','comparer_truths']:\n",
    "    missing_columns = ['CITY','STATE','ZIP_CODE','UNKNOWN']\n",
    "    raw_address_list_1 = stndrdzr.empty_column_addition(raw_address_list_1, missing_columns)\n",
    "    raw_address_list_2 = stndrdzr.empty_column_addition(raw_address_list_2, missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call the trained CRF Tagger on the 2 lists of raw addresses\n",
    "if run_mode in ['comparer','comparer_truths']:\n",
    "    at = AddressTagger()\n",
    "    tagged_address_list_1 = at.series_to_address_df(raw_address_list_1[field_name_raw_addresses], standardize = standardize_addresses)\n",
    "    tagged_address_list_2 = at.series_to_address_df(raw_address_list_2[field_name_raw_addresses], standardize = standardize_addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check for Errors in Zip Codes and Replace City Names with Primary City from Zip Code\n",
    "raw_address_list_1 = stndrdzr.fix_cities_zips(raw_address_list_1)\n",
    "raw_address_list_2 = stndrdzr.fix_cities_zips(raw_address_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add Remaining Columns from Raw Address Dataframes to Tagged Address Dataframes\n",
    "joined_address_list_1 = tagged_address_list_1.join(raw_address_list_1[['Record_ID','CITY','STATE','ZIP_CODE','UNKNOWN','Zip_Code_Error']])\n",
    "joined_address_list_2 = tagged_address_list_2.join(raw_address_list_2[['Record_ID','CITY','STATE','ZIP_CODE','UNKNOWN','Zip_Code_Error']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove Addresses with Zip Code Errors (I.e., where the Zip Code is not valid for the given state)\n",
    "error_addresses_list_1 = joined_address_list_1.where(joined_address_list_1.Zip_Code_Error == \"Yes\").dropna()\n",
    "error_addresses_list_2 = joined_address_list_2.where(joined_address_list_2.Zip_Code_Error == \"Yes\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only Addresses without Zip Code Errors (I.e., where the Zip Code is valid for the given state)\n",
    "nonerror_addresses_list_1 = joined_address_list_1.where(joined_address_list_1.Zip_Code_Error == \"No\").dropna()\n",
    "nonerror_addresses_list_2 = joined_address_list_2.where(joined_address_list_2.Zip_Code_Error == \"No\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nonerror_addresses_list_1 = nonerror_addresses_list_1.astype({'Record_ID':'int', 'ZIP_CODE':'int'})\n",
    "nonerror_addresses_list_2 = nonerror_addresses_list_2.astype({'Record_ID':'int', 'ZIP_CODE':'int'})\n",
    "nonerror_addresses_list_1 = nonerror_addresses_list_1.astype({'Record_ID':'str', 'ZIP_CODE':'str'})\n",
    "nonerror_addresses_list_2 = nonerror_addresses_list_2.astype({'Record_ID':'str', 'ZIP_CODE':'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Intra-Grouping of Tagged Address Lists to Consolidate Duplicates\n",
    "if run_mode == 'comparer':\n",
    "    grouped_address_list_1 = stndrdzr.consolidate_address_list(nonerror_addresses_list_1)\n",
    "    grouped_address_list_2 = stndrdzr.consolidate_address_list(nonerror_addresses_list_2)\n",
    "else:\n",
    "    grouped_address_list_1 = nonerror_addresses_list_1.copy()\n",
    "    grouped_address_list_2 = nonerror_addresses_list_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call Either the Exact Match or Learning Match Functions to match the 2 lists\n",
    "exact_matches = mtch.exact_matcher(grouped_address_list_1, grouped_address_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unmatched_address_list_1 = grouped_address_list_1.mask(grouped_address_list_1.Record_ID.isin(exact_matches['Record_ID_list_1'])).dropna()\n",
    "unmatched_address_list_2 = grouped_address_list_2.mask(grouped_address_list_2.Record_ID.isin(exact_matches['Record_ID_list_2'])).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionary of DataFrames for Excel File\n",
    "dataframes_for_excel = {'raw_addresses_list_1': raw_address_list_1, 'raw_addresses_list2': raw_address_list_2,\n",
    "                        'zip_errors_list1': error_addresses_list_1, 'zip_errors_list2': error_addresses_list_2,\n",
    "                       'exact_matches': exact_matches, 'unmatched_list_1': unmatched_address_list_1,\n",
    "                       'unmatched_list_2': unmatched_address_list_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write Dict of DataFrames to Excel\n",
    "writer = pd.ExcelWriter('output\\\\raw_to_matched_addresses.xlsx', engine='xlsxwriter')\n",
    "for sheet, frame in  dataframes_for_excel.items():\n",
    "    frame.to_excel(writer, sheet_name = sheet)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare Output of Exact Match to Manually Tagged Matches\n",
    "if run_mode in ['comparer_truths','all']:\n",
    "    manual_matches = pd.read_excel(file_name_ground_truth_matches, dtype=str)\n",
    "    golden_exact_matches = manual_matches.where(manual_matches.Match_Type.isin([\"Exact\",\"Standardized Exact\"])).dropna().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Record_ID_list_1 Record_ID_list_2 row_index_list_1 row_index_list_2\n",
      "0                  1                1                0                0\n",
      "1                  3                2                1                1\n",
      "2                  4                3                2                2\n",
      "3                  5                4                3                3\n",
      "4                  6                5                4                4\n",
      "5                  7                6                5                5\n",
      "6                  8                7                6                6\n",
      "7                 11                8                7                7\n",
      "8                 12                9                8                8\n",
      "9                 13               10                9                9\n",
      "10                14               12               10               10\n",
      "11                15               13               11               11\n",
      "12                16               14               12               12\n",
      "13                17               15               13               13\n",
      "14                18               16               14               14\n",
      "15                19               17               15               15\n",
      "16                20               18               16               16\n",
      "17                21               19               17               17\n",
      "18                22               20               18               18\n",
      "19                23               21               19               19\n",
      "20                24               22               20               20\n",
      "21                25               23               21               21\n",
      "22                26               24               22               22\n",
      "23                27               25               23               23\n",
      "24                28               26               24               24\n",
      "25                29               28               25               25\n",
      "26                30               29               26               26\n",
      "27                31               30               27               27\n",
      "28                32               31               28               28\n",
      "29                33               32               29               29\n",
      "..               ...              ...              ...              ...\n",
      "583              707              632              583              584\n",
      "584              708              633              584              585\n",
      "585              709              634              585              586\n",
      "586              710              635              586              587\n",
      "587              711              636              587              588\n",
      "588              712              637              588              589\n",
      "589              714              638              589              590\n",
      "590              715              639              590              591\n",
      "591              716              640              591              592\n",
      "592              717              641              592              593\n",
      "593              718              642              593              594\n",
      "594              719              643              594              595\n",
      "595              720              644              595              596\n",
      "596              722              645              596              597\n",
      "597              723              647              597              598\n",
      "598              724              648              598              599\n",
      "599              725              649              599              600\n",
      "600              726              650              600              601\n",
      "601              727              651              601              602\n",
      "602              728              652              602              603\n",
      "603              732              653              603              604\n",
      "604              733              654              604              605\n",
      "605              735              657              605              606\n",
      "606              736              658              606              607\n",
      "607              737              659              607              608\n",
      "608              738              660              608              609\n",
      "609              740              661              609              610\n",
      "610              741              662              610              611\n",
      "611              743              663              611              612\n",
      "612              744              664              612              613\n",
      "\n",
      "[613 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "if run_mode in ['comparer_truths','all']:\n",
    "    join_cols = ['Record_ID_list_1','Record_ID_list_2']\n",
    "    subset_columns_exact_matches = exact_matches[join_cols].copy()\n",
    "    subset_columns_exact_matches['row_index'] = subset_columns_exact_matches.index\n",
    "    subset_cols_golden_exact_matches = golden_exact_matches[join_cols].copy()\n",
    "    subset_cols_golden_exact_matches['row_index'] = subset_cols_golden_exact_matches.index\n",
    "    \n",
    "    subset_columns_exact_matches = subset_columns_exact_matches.astype(str)\n",
    "    subset_cols_golden_exact_matches = subset_cols_golden_exact_matches.astype(str)\n",
    "    \n",
    "    test_vs_golden_compare = mtch.exact_matcher(subset_columns_exact_matches, subset_cols_golden_exact_matches, join_cols)\n",
    "    print (test_vs_golden_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Record_ID_list_1 Record_ID_list_2 row_index\n",
      "89              105              303        89\n"
     ]
    }
   ],
   "source": [
    "if run_mode in ['comparer_truths','all']:\n",
    "    missing_golden_matches = subset_cols_golden_exact_matches.mask(subset_cols_golden_exact_matches.row_index.isin(test_vs_golden_compare.row_index_list_2)).dropna()\n",
    "    print (missing_golden_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Record_ID_list_1, Record_ID_list_2, row_index]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "if run_mode in ['comparer_truths','all']:\n",
    "    matches_not_in_golden = subset_columns_exact_matches.mask(subset_columns_exact_matches.row_index.isin(test_vs_golden_compare.row_index_list_1)).dropna()\n",
    "    print (matches_not_in_golden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list 1 accuracy =  0.9986577181208054\n",
      "list 2 accuracy =  0.9984423676012462\n",
      "precision =  1.0\n",
      "recall =  0.998371335504886\n"
     ]
    }
   ],
   "source": [
    "if run_mode in ['comparer_truths','all']:\n",
    "    total_records_list_1 = raw_address_list_1.shape[0]\n",
    "    total_records_list_2 = raw_address_list_2.shape[0]\n",
    "    total_modeled_matches = exact_matches.shape[0]\n",
    "    total_manual_exact_matches = golden_exact_matches.shape[0]\n",
    "    total_correct_positive_matches = test_vs_golden_compare.shape[0]\n",
    "    false_negatives = missing_golden_matches.shape[0]\n",
    "    false_positives = matches_not_in_golden.shape[0]\n",
    "    \n",
    "    accuracy_list_1 = (total_records_list_1 - (false_negatives + false_positives)) / total_records_list_1\n",
    "    accuracy_list_2 = (total_records_list_2 - (false_negatives + false_positives)) / total_records_list_2\n",
    "    precision = total_correct_positive_matches / (total_correct_positive_matches + false_positives)\n",
    "    recall = total_correct_positive_matches / (total_correct_positive_matches + false_negatives)\n",
    "    \n",
    "    print ('list 1 accuracy = ', accuracy_list_1)\n",
    "    print ('list 2 accuracy = ', accuracy_list_2)\n",
    "    print ('precision = ', precision)\n",
    "    print ('recall = ', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run Single File against Tagger and Calculate Accuracy\n",
    "#if run_mode == 'tagger':\n",
    "#    test_file = pd.read_excel(file_location_raw_addresses_1, keep_default_na=False, dtype=str)\n",
    "#    test_file = stndrdzr.record_id_addition(test_file, field_name_record_id)\n",
    "    \n",
    "#    tagger = AddressTagger()\n",
    "#    tagged_test_file = tagger.series_to_address_df(test_file[field_name_raw_addresses], standardize = standardize_addresses)\n",
    "#    crf_tagged_test_file = tagged_test_file.join(test_file['Record_ID'])\n",
    "    \n",
    "#    ground_truth_columns = ['Record_ID', 'Tagged Street Number','Tagged Pre Street Direction','Tagged Street Name','Tagged Street Type','Tagged Post Street Direction','Tagged Unit Type','Tagged Unit Number']\n",
    "    \n",
    "#    manual_tagged_test_file = test_file[ground_truth_columns].copy()\n",
    "#    manual_tagged_test_file = manual_tagged_test_file.rename(columns={'Tagged Street Number':'STREET_NUMBER',\n",
    "#                                                                     'Tagged Pre Street Direction':'PRE_DIRECTION',\n",
    "#                                                                     'Tagged Street Name':'STREET_NAME',\n",
    "#                                                                     'Tagged Street Type':'STREET_TYPE',\n",
    "#                                                                     'Tagged Post Street Direction':'POST_DIRECTION',\n",
    "#                                                                     'Tagged Unit Type':'UNIT_TYPE',\n",
    "#                                                                     'Tagged Unit Number':'UNIT_NUMBER'})\n",
    "\n",
    "#    cols_for_matcher = ['UNIT_TYPE','UNIT_NUMBER','STREET_NUMBER','PRE_DIRECTION','STREET_NAME','STREET_TYPE','POST_DIRECTION']\n",
    "#    correctly_tagged_addresses = mtch.exact_matcher(crf_tagged_test_file, manual_tagged_test_file, cols_for_matcher)\n",
    "    \n",
    "#    incorrectly_tagged_addresses = crf_tagged_test_file.mask(crf_tagged_test_file.Record_ID.isin(correctly_tagged_addresses['Record_ID_list_1'])).dropna()\n",
    "#    incorrectly_tagged_addresses = incorrectly_tagged_addresses.merge(test_file[ground_truth_columns], on='Record_ID')\n",
    "\n",
    "#    total_records = crf_tagged_test_file.shape[0]\n",
    "#    correctly_tagged = correctly_tagged_addresses.shape[0]\n",
    "#    incorrectly_tagged = incorrectly_tagged_addresses.shape[0]\n",
    "    \n",
    "#    tagger_accuracy = correctly_tagged / total_records\n",
    "#    print ('tagger accuracy = ', tagger_accuracy)\n",
    "    \n",
    "#    for col in cols_for_matcher:\n",
    "#        precision, recall, fscore, ignore = sklearn.metrics.precision_recall_fscore_support(manual_tagged_test_file[col], crf_tagged_test_file[col], average='micro')\n",
    "#        print ('column = ', col, 'precision = ', precision, 'recall = ', recall, 'f1score = ',fscore)\n",
    "    \n",
    "    # Dictionary of DataFrames for Excel Tagger Test File\n",
    "#    dataframes_for_tagger_excel = {'test_data_file': test_file, \n",
    "#                                   'crf_tagger_output': crf_tagged_test_file,\n",
    "#                                   'ground_truth_test_file': manual_tagged_test_file, \n",
    "#                                   'correctly_tagged': correctly_tagged_addresses,\n",
    "#                                   'incorrectly_tagged': incorrectly_tagged_addresses}\n",
    "    \n",
    "#    # Write Dict of DataFrames to Excel\n",
    "#    tagger_writer = pd.ExcelWriter('output\\\\tagger accuracy output.xlsx', engine='xlsxwriter')\n",
    "#    for sheet, frame in  dataframes_for_tagger_excel.items():\n",
    "#        frame.to_excel(tagger_writer, sheet_name = sheet)\n",
    "#    tagger_writer.save()\n",
    "    \n",
    "#    sys.exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
