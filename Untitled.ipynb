{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIRECTIONS = ['n','s','e','w','ne','nw','se','sw','north','south','east','west']\n",
    "STREET_NAMES = {'alley',\n",
    " 'aly',\n",
    " 'annex',\n",
    " 'anx',\n",
    " 'arc',\n",
    " 'arcade',\n",
    " 'av',\n",
    " 'ave',\n",
    " 'avenue',\n",
    " 'bayoo',\n",
    " 'bch',\n",
    " 'beach',\n",
    " 'bend',\n",
    " 'bg',\n",
    " 'bgs',\n",
    " 'bl',\n",
    " 'blf',\n",
    " 'bluff',\n",
    " 'blvd',\n",
    " 'bnd',\n",
    " 'bottom',\n",
    " 'boulevard',\n",
    " 'br',\n",
    " 'branch',\n",
    " 'brg',\n",
    " 'bridge',\n",
    " 'brk',\n",
    " 'brks',\n",
    " 'brook',\n",
    " 'brooks',\n",
    " 'btm',\n",
    " 'burg',\n",
    " 'burgs',\n",
    " 'byp',\n",
    " 'bypass',\n",
    " 'byu',\n",
    " 'camp',\n",
    " 'canyon',\n",
    " 'cape',\n",
    " 'causeway',\n",
    " 'center',\n",
    " 'centers',\n",
    " 'ci',\n",
    " 'cir',\n",
    " 'circle',\n",
    " 'circles',\n",
    " 'cirs',\n",
    " 'cl',\n",
    " 'clb',\n",
    " 'clf',\n",
    " 'clfs',\n",
    " 'cliff',\n",
    " 'cliffs',\n",
    " 'close',\n",
    " 'club',\n",
    " 'cmn',\n",
    " 'common',\n",
    " 'cor',\n",
    " 'corner',\n",
    " 'corners',\n",
    " 'cors',\n",
    " 'course',\n",
    " 'court',\n",
    " 'courts',\n",
    " 'cove',\n",
    " 'coves',\n",
    " 'cp',\n",
    " 'cpe',\n",
    " 'cr',\n",
    " 'creek',\n",
    " 'cres',\n",
    " 'crescent',\n",
    " 'crest',\n",
    " 'crk',\n",
    " 'crossing',\n",
    " 'crossroad',\n",
    " 'crse',\n",
    " 'crst',\n",
    " 'crt',\n",
    " 'cswy',\n",
    " 'ct',\n",
    " 'ctr',\n",
    " 'ctrs',\n",
    " 'cts',\n",
    " 'curv',\n",
    " 'curve',\n",
    " 'cv',\n",
    " 'cvs',\n",
    " 'cyn',\n",
    " 'dale',\n",
    " 'dam',\n",
    " 'dgnl',\n",
    " 'diagonal',\n",
    " 'divide',\n",
    " 'dl',\n",
    " 'dm',\n",
    " 'dr',\n",
    " 'drive',\n",
    " 'drives',\n",
    " 'drs',\n",
    " 'dv',\n",
    " 'est',\n",
    " 'estate',\n",
    " 'estates',\n",
    " 'ests',\n",
    " 'ewy',\n",
    " 'expressway',\n",
    " 'expwy',\n",
    " 'expy',\n",
    " 'ext',\n",
    " 'extension',\n",
    " 'extensions',\n",
    " 'exts',\n",
    " 'falls',\n",
    " 'ferry',\n",
    " 'field',\n",
    " 'fields',\n",
    " 'flat',\n",
    " 'flats',\n",
    " 'fld',\n",
    " 'flds',\n",
    " 'fls',\n",
    " 'flt',\n",
    " 'flts',\n",
    " 'ford',\n",
    " 'fords',\n",
    " 'forest',\n",
    " 'forge',\n",
    " 'forges',\n",
    " 'fork',\n",
    " 'forks',\n",
    " 'fort',\n",
    " 'frd',\n",
    " 'frds',\n",
    " 'freeway',\n",
    " 'frg',\n",
    " 'frgs',\n",
    " 'frk',\n",
    " 'frks',\n",
    " 'frst',\n",
    " 'fry',\n",
    " 'ft',\n",
    " 'garden',\n",
    " 'gardens',\n",
    " 'gateway',\n",
    " 'gdn',\n",
    " 'gdns',\n",
    " 'glen',\n",
    " 'glens',\n",
    " 'gln',\n",
    " 'glns',\n",
    " 'grade',\n",
    " 'grd',\n",
    " 'green',\n",
    " 'greens',\n",
    " 'grn',\n",
    " 'grns',\n",
    " 'grove',\n",
    " 'groves',\n",
    " 'grv',\n",
    " 'grvs',\n",
    " 'gtwy',\n",
    " 'harbor',\n",
    " 'harbours',\n",
    " 'haven',\n",
    " 'hbr',\n",
    " 'hbrs',\n",
    " 'heights',\n",
    " 'highway',\n",
    " 'hill',\n",
    " 'hills',\n",
    " 'hl',\n",
    " 'hls',\n",
    " 'hollow',\n",
    " 'holw',\n",
    " 'hts',\n",
    " 'hvn',\n",
    " 'hwy',\n",
    " 'inlet',\n",
    " 'inlt',\n",
    " 'is',\n",
    " 'island',\n",
    " 'islands',\n",
    " 'iss',\n",
    " 'jct',\n",
    " 'jcts',\n",
    " 'jr',\n",
    " 'junction',\n",
    " 'junctions',\n",
    " 'junior',\n",
    " 'k',\n",
    " 'knl',\n",
    " 'knls',\n",
    " 'knoll',\n",
    " 'knolls',\n",
    " 'ks',\n",
    " 'ky',\n",
    " 'kys',\n",
    " 'la',\n",
    " 'lake',\n",
    " 'lakes',\n",
    " 'landing',\n",
    " 'lane',\n",
    " 'lck',\n",
    " 'lcks',\n",
    " 'ldg',\n",
    " 'lf',\n",
    " 'lgt',\n",
    " 'lgts',\n",
    " 'light',\n",
    " 'lights',\n",
    " 'lk',\n",
    " 'lks',\n",
    " 'ln',\n",
    " 'lndg',\n",
    " 'loaf',\n",
    " 'lock',\n",
    " 'locks',\n",
    " 'lodge',\n",
    " 'loop',\n",
    " 'lp',\n",
    " 'mal',\n",
    " 'mall',\n",
    " 'manor',\n",
    " 'manors',\n",
    " 'mdw',\n",
    " 'mdws',\n",
    " 'meadow',\n",
    " 'meadows',\n",
    " 'mill',\n",
    " 'mills',\n",
    " 'mission',\n",
    " 'ml',\n",
    " 'mls',\n",
    " 'mnr',\n",
    " 'mnrs',\n",
    " 'motorway',\n",
    " 'mount',\n",
    " 'mountain',\n",
    " 'mountains',\n",
    " 'msn',\n",
    " 'mt',\n",
    " 'mtn',\n",
    " 'mtns',\n",
    " 'mtwy',\n",
    " 'nck',\n",
    " 'neck',\n",
    " 'opas',\n",
    " 'orch',\n",
    " 'orchard',\n",
    " 'oval',\n",
    " 'overpass',\n",
    " 'ovps',\n",
    " 'park',\n",
    " 'parkway',\n",
    " 'passage',\n",
    " 'pine',\n",
    " 'pines',\n",
    " 'pk',\n",
    " 'pkwy',\n",
    " 'pky',\n",
    " 'pl',\n",
    " 'place',\n",
    " 'plain',\n",
    " 'plains',\n",
    " 'plaza',\n",
    " 'pln',\n",
    " 'plns',\n",
    " 'plz',\n",
    " 'pne',\n",
    " 'pnes',\n",
    " 'point',\n",
    " 'points',\n",
    " 'port',\n",
    " 'ports',\n",
    " 'pr',\n",
    " 'prairie',\n",
    " 'prt',\n",
    " 'prts',\n",
    " 'psge',\n",
    " 'pt',\n",
    " 'pts',\n",
    " 'pw',\n",
    " 'radial',\n",
    " 'radl',\n",
    " 'ranch',\n",
    " 'range',\n",
    " 'rapid',\n",
    " 'rapids',\n",
    " 'rd',\n",
    " 'rdg',\n",
    " 'rdgs',\n",
    " 'rds',\n",
    " 'rest',\n",
    " 'rge',\n",
    " 'ridge',\n",
    " 'ridges',\n",
    " 'riv',\n",
    " 'river',\n",
    " 'rnch',\n",
    " 'road',\n",
    " 'roads',\n",
    " 'route',\n",
    " 'rpd',\n",
    " 'rpds',\n",
    " 'rst',\n",
    " 'rte',\n",
    " 'senior',\n",
    " 'shl',\n",
    " 'shls',\n",
    " 'shoal',\n",
    " 'shoals',\n",
    " 'shore',\n",
    " 'shores',\n",
    " 'shr',\n",
    " 'shrs',\n",
    " 'skwy',\n",
    " 'skyway',\n",
    " 'smt',\n",
    " 'spg',\n",
    " 'spgs',\n",
    " 'spring',\n",
    " 'springs',\n",
    " 'sq',\n",
    " 'sqs',\n",
    " 'square',\n",
    " 'squares',\n",
    " 'sr',\n",
    " 'sta',\n",
    " 'station',\n",
    " 'stra',\n",
    " 'stravenue',\n",
    " 'stream',\n",
    " 'streets',\n",
    " 'strm',\n",
    " 'sts',\n",
    " 'summit',\n",
    " 'te',\n",
    " 'ter',\n",
    " 'terr',\n",
    " 'terrace',\n",
    " 'tfwy',\n",
    " 'thfr',\n",
    " 'thoroughfare',\n",
    " 'throughway',\n",
    " 'thruway',\n",
    " 'thwy',\n",
    " 'township',\n",
    " 'tpke',\n",
    " 'tr',\n",
    " 'trace',\n",
    " 'track',\n",
    " 'trafficway',\n",
    " 'trail',\n",
    " 'trak',\n",
    " 'trce',\n",
    " 'trfy',\n",
    " 'trl',\n",
    " 'trwy',\n",
    " 'tunl',\n",
    " 'tunnel',\n",
    " 'turnpike',\n",
    " 'twp',\n",
    " 'un',\n",
    " 'underpass',\n",
    " 'union',\n",
    " 'unions',\n",
    " 'unp',\n",
    " 'uns',\n",
    " 'upas',\n",
    " 'valley',\n",
    " 'valleys',\n",
    " 'via',\n",
    " 'viaduct',\n",
    " 'view',\n",
    " 'views',\n",
    " 'village',\n",
    " 'villages',\n",
    " 'ville',\n",
    " 'vis',\n",
    " 'vista',\n",
    " 'vl',\n",
    " 'vlg',\n",
    " 'vlgs',\n",
    " 'vly',\n",
    " 'vlys',\n",
    " 'vw',\n",
    " 'vws',\n",
    " 'walkway',\n",
    " 'way',\n",
    " 'well',\n",
    " 'wells',\n",
    " 'wkwy',\n",
    " 'wl',\n",
    " 'wls',\n",
    " 'wy',\n",
    " 'xing',\n",
    " 'xrd'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource 'tokenizers/punkt/english.pickle' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - 'C:\\\\Users\\\\colin/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Users\\\\colin\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\colin\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\colin\\\\AppData\\\\Roaming\\\\nltk_data'\n    - ''\n**********************************************************************",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-8c1b9f7ca7e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtokenize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"hello there\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\colin\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserver_line\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \"\"\"\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m     return [token for sent in sentences\n\u001b[0;32m    132\u001b[0m             for token in _treebank_word_tokenizer.tokenize(sent)]\n",
      "\u001b[1;32mC:\\Users\\colin\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \"\"\"\n\u001b[1;32m---> 96\u001b[1;33m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\colin\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raw'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\colin\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'nltk'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'file'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m         \u001b[1;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\colin\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    651\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'*'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n%s\\n%s\\n%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 653\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource 'tokenizers/punkt/english.pickle' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - 'C:\\\\Users\\\\colin/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Users\\\\colin\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\colin\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\colin\\\\AppData\\\\Roaming\\\\nltk_data'\n    - ''\n**********************************************************************"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
